model_config:
  model_name: openlm-research/open_llama_3b_v2
  model_kwargs:
    pretrained_model_name_or_path: openlm-research/open_llama_3b_v2
    trust_remote_code: True
    device_map: auto
    cache_dir: _cache_models/

dataset_config:
  dataset_name: gsm8k
  dataset_kwargs:
    path: gsm8k
    name: main
    split: test
    cache_dir: _cache_data/

prompt_config:
  prompt_name: GSM8K_COT_STEP_FEWSHOT

generation_kwargs:
  max_new_tokens: 200
  do_sample: False

until:
  - "Question:"
  - "Question: "
  - "\n\n"
  - "Q: "

batch_size: 4
padding_size: left
truncation: False
seed: 0
device: cuda
limit: 20